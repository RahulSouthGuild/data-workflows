# Multi-Tenant Data Workflows - Directory Structure Reference

> **Last Updated:** 2025-01-15
> **Purpose:** Production-ready multi-tenant ETL pipeline for StarRocks
> **Scale:** Optimized for 2-5 tenants, scalable to 20+

---

## Complete Directory Structure

```
data-workflows/
â”‚
â”œâ”€â”€ core/                                    # SHARED CODE (business-agnostic)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ extractors/                         # File extraction
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ csv_extractor.py                # Generic CSV reader
â”‚   â”‚   â”œâ”€â”€ excel_extractor.py              # Generic Excel reader (xlsx, xls)
â”‚   â”‚   â””â”€â”€ azure_blob_extractor.py         # Generic Azure blob downloader
â”‚   â”‚
â”‚   â”œâ”€â”€ transformers/                       # Data transformation
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ file_to_parquet.py              # Universal converter (CSV/Excel/Parquet)
â”‚   â”‚   â”‚                                   # - Converts CSV â†’ Parquet
â”‚   â”‚   â”‚                                   # - Converts Excel â†’ Parquet
â”‚   â”‚   â”‚                                   # - Copies Parquet â†’ raw_parquet
â”‚   â”‚   â”œâ”€â”€ dtype_transformer.py            # Generic dtype conversion
â”‚   â”‚   â”œâ”€â”€ column_mapper.py                # Generic column renaming
â”‚   â”‚   â”œâ”€â”€ roundoff_transformer.py         # Generic numeric rounding
â”‚   â”‚   â””â”€â”€ transformation_engine.py        # Orchestrates all transformations
â”‚   â”‚
â”‚   â””â”€â”€ loaders/                            # Data loading
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ starrocks_loader.py             # Generic StarRocks Stream Load API
â”‚
â”œâ”€â”€ orchestration/                           # MULTI-TENANT ORCHESTRATION
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ tenant_manager.py                   # TenantConfig & TenantManager classes
â”‚   â”‚                                       # - Loads tenant_registry.yaml
â”‚   â”‚                                       # - Manages tenant configurations
â”‚   â”‚                                       # - Provides tenant iteration
â”‚   â”œâ”€â”€ tenant_job_runner.py                # Sequential job execution
â”‚   â”‚                                       # - Runs jobs tenant1 â†’ tenant2 â†’ tenant3
â”‚   â”‚                                       # - Handles failures gracefully
â”‚   â””â”€â”€ scheduler_integration.py            # Cron/APScheduler integration
â”‚
â”œâ”€â”€ configs/                                 # CONFIGURATION LAYER
â”‚   â”œâ”€â”€ tenant_registry.yaml                # â­ Master list of all tenants
â”‚   â”‚                                       # - enabled/disabled status
â”‚   â”‚                                       # - tenant metadata
â”‚   â”‚                                       # - schedule priorities
â”‚   â”‚
â”‚   â”œâ”€â”€ shared/                             # Shared defaults (all tenants)
â”‚   â”‚   â”œâ”€â”€ default_config.yaml             # Default settings
â”‚   â”‚   â””â”€â”€ common_business_rules.yaml      # Common validation rules
â”‚   â”‚
â”‚   â”œâ”€â”€ starrocks/                          # StarRocks-specific configs
â”‚   â”‚   â”œâ”€â”€ connection_pool.yaml            # Connection pool settings
â”‚   â”‚   â””â”€â”€ stream_load_defaults.yaml       # Stream Load defaults
â”‚   â”‚
â”‚   â””â”€â”€ tenants/                            # â­ Per-tenant configurations
â”‚       â”‚
â”‚       â”œâ”€â”€ tenant1/                        # Client 1 (e.g., "pidilite_mumbai")
â”‚       â”‚   â”œâ”€â”€ config.yaml                 # Tenant metadata (DB name, paths, etc.)
â”‚       â”‚   â”œâ”€â”€ .env                        # âš ï¸ SECRETS (gitignored!)
â”‚       â”‚   â”‚
â”‚       â”‚   â”œâ”€â”€ schemas/                    # Database schema definitions
â”‚       â”‚   â”‚   â”œâ”€â”€ tables/
â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ 01_dim_material_mapping.py
â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ 02_dim_customer_master.py
â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ 03_dim_dealer_master.py
â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ 04_dim_hierarchy.py
â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ 05_dim_sales_group.py
â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ 06_dim_material.py
â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ 07_fact_invoice_details.py
â”‚       â”‚   â”‚   â”‚   â””â”€â”€ 08_fact_invoice_secondary.py
â”‚       â”‚   â”‚   â”œâ”€â”€ views/
â”‚       â”‚   â”‚   â”‚   â”œâ”€â”€ 01_secondary_sales_view.py
â”‚       â”‚   â”‚   â”‚   â””â”€â”€ 02_primary_sales_view.py
â”‚       â”‚   â”‚   â””â”€â”€ matviews/
â”‚       â”‚   â”‚       â””â”€â”€ 01_secondary_sales_matview.py
â”‚       â”‚   â”‚
â”‚       â”‚   â”œâ”€â”€ column_mappings/            # CSV â†’ DB column mappings
â”‚       â”‚   â”‚   â”œâ”€â”€ 01_dim_material_mapping.yaml
â”‚       â”‚   â”‚   â”œâ”€â”€ 02_dim_customer_master.yaml
â”‚       â”‚   â”‚   â”œâ”€â”€ 03_dim_dealer_master.yaml
â”‚       â”‚   â”‚   â”œâ”€â”€ 04_dim_hierarchy.yaml
â”‚       â”‚   â”‚   â”œâ”€â”€ 05_dim_sales_group.yaml
â”‚       â”‚   â”‚   â”œâ”€â”€ 06_dim_material.yaml
â”‚       â”‚   â”‚   â”œâ”€â”€ 07_fact_invoice_details.yaml
â”‚       â”‚   â”‚   â””â”€â”€ 08_fact_invoice_secondary.yaml
â”‚       â”‚   â”‚
â”‚       â”‚   â”œâ”€â”€ computed_columns.yaml       # Computed column definitions
â”‚       â”‚   â”‚
â”‚       â”‚   â”œâ”€â”€ business_logic/             # Business-specific logic
â”‚       â”‚   â”‚   â”œâ”€â”€ business_constants.py   # Filter dimensions configuration
â”‚       â”‚   â”‚   â”œâ”€â”€ validation_rules.py     # Custom validation rules
â”‚       â”‚   â”‚   â””â”€â”€ rls_config.py           # Row-level security policies
â”‚       â”‚   â”‚
â”‚       â”‚   â””â”€â”€ seeds/                      # Reference data
â”‚       â”‚       â”œâ”€â”€ SEED_MAPPING.py         # Seed table configuration
â”‚       â”‚       â”œâ”€â”€ DimMaterialMapping.csv
â”‚       â”‚       â””â”€â”€ DimSalesGroup.csv
â”‚       â”‚
â”‚       â”œâ”€â”€ tenant2/                        # Client 2
â”‚       â”‚   â””â”€â”€ ... (same structure as tenant1)
â”‚       â”‚
â”‚       â”œâ”€â”€ tenant3/                        # Client 3
â”‚       â”‚   â””â”€â”€ ... (same structure)
â”‚       â”‚
â”‚       â””â”€â”€ _template/                      # â­ Template for new tenant onboarding
â”‚           â”œâ”€â”€ config.yaml.template
â”‚           â”œâ”€â”€ .env.template
â”‚           â”œâ”€â”€ schemas/
â”‚           â”‚   â”œâ”€â”€ tables/
â”‚           â”‚   â”œâ”€â”€ views/
â”‚           â”‚   â””â”€â”€ matviews/
â”‚           â”œâ”€â”€ column_mappings/
â”‚           â”œâ”€â”€ computed_columns.yaml
â”‚           â”œâ”€â”€ business_logic/
â”‚           â””â”€â”€ seeds/
â”‚
â”œâ”€â”€ data/                                    # DATA LAYER (per-tenant isolation)
â”‚   â”œâ”€â”€ tenant1/
â”‚   â”‚   â”œâ”€â”€ historical/
â”‚   â”‚   â”‚   â”œâ”€â”€ source_files/               # ğŸ“¥ Raw files (CSV, Excel, Parquet)
â”‚   â”‚   â”‚   â”‚                               # - Downloaded from Azure blob
â”‚   â”‚   â”‚   â”‚                               # - Decompressed (.gz â†’ .csv/.xlsx)
â”‚   â”‚   â”‚   â”œâ”€â”€ raw_parquet/                # ğŸŸ¤ Bronze: Converted to parquet
â”‚   â”‚   â”‚   â”‚                               # - CSV â†’ Parquet
â”‚   â”‚   â”‚   â”‚                               # - Excel â†’ Parquet
â”‚   â”‚   â”‚   â”‚                               # - Parquet â†’ Parquet (copy)
â”‚   â”‚   â”‚   â”‚                               # - NO transformations applied
â”‚   â”‚   â”‚   â””â”€â”€ cleaned_parquet/            # ğŸ¥ˆ Silver: Transformed & validated
â”‚   â”‚   â”‚       â”œâ”€â”€ DimMaterialMapping.parquet
â”‚   â”‚   â”‚       â”œâ”€â”€ FactInvoiceDetails.parquet
â”‚   â”‚   â”‚       â””â”€â”€ ...
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ incremental/                    # Same structure as historical
â”‚   â”‚   â”‚   â”œâ”€â”€ source_files/
â”‚   â”‚   â”‚   â”œâ”€â”€ raw_parquet/
â”‚   â”‚   â”‚   â””â”€â”€ cleaned_parquet/
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ temp/                           # Temporary processing files
â”‚   â”‚       â””â”€â”€ ... (auto-cleaned)
â”‚   â”‚
â”‚   â”œâ”€â”€ tenant2/
â”‚   â”‚   â””â”€â”€ ... (same structure)
â”‚   â”‚
â”‚   â”œâ”€â”€ tenant3/
â”‚   â”‚   â””â”€â”€ ... (same structure)
â”‚   â”‚
â”‚   â””â”€â”€ .gitkeep                            # Track empty directory in git
â”‚
â”œâ”€â”€ logs/                                    # LOGS (per-tenant isolation)
â”‚   â”œâ”€â”€ tenant1/
â”‚   â”‚   â”œâ”€â”€ scheduler/                      # Cron job logs
â”‚   â”‚   â”‚   â”œâ”€â”€ evening_dimension_sync.log
â”‚   â”‚   â”‚   â”œâ”€â”€ morning_fis_incremental.log
â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â”œâ”€â”€ etl/                            # ETL pipeline logs
â”‚   â”‚   â”‚   â”œâ”€â”€ extraction.log
â”‚   â”‚   â”‚   â”œâ”€â”€ transformation.log
â”‚   â”‚   â”‚   â””â”€â”€ loading.log
â”‚   â”‚   â””â”€â”€ notifications/                  # Email notification logs
â”‚   â”‚
â”‚   â”œâ”€â”€ tenant2/
â”‚   â”‚   â””â”€â”€ ... (same structure)
â”‚   â”‚
â”‚   â””â”€â”€ tenant3/
â”‚       â””â”€â”€ ... (same structure)
â”‚
â”œâ”€â”€ utils/                                   # UTILITIES
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ etl_orchestrator.py                 # Pipeline executor (tenant-aware)
â”‚   â”‚                                       # - Extract â†’ Transform â†’ Load
â”‚   â”‚                                       # - Accepts TenantConfig parameter
â”‚   â”œâ”€â”€ schema_validator.py                 # Schema validation
â”‚   â”œâ”€â”€ pipeline_config.py                  # Config loader helpers
â”‚   â””â”€â”€ logging_config.py                   # Logging setup (per-tenant)
â”‚
â”œâ”€â”€ db/                                      # DATABASE MANAGEMENT SCRIPTS
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ create_tables.py                    # â­ Table creation (tenant-aware)
â”‚   â”‚                                       # - Loads from configs/tenants/{id}/schemas/
â”‚   â”‚                                       # - Shows which tenant is being processed
â”‚   â”œâ”€â”€ load_seed_data.py                   # Seed data loader (tenant-aware)
â”‚   â”œâ”€â”€ populate_business_constants.py      # Business constants (tenant-aware)
â”‚   â””â”€â”€ migrations/                         # Schema migration scripts
â”‚       â””â”€â”€ README.md
â”‚
â”œâ”€â”€ scheduler/                               # JOB SCHEDULER
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ orchestrator.py                     # â­ Main scheduler (updated)
â”‚   â”‚                                       # - Iterates over enabled tenants
â”‚   â”‚                                       # - Calls tenant_job_runner
â”‚   â”œâ”€â”€ crontab.yaml                        # Job schedules
â”‚   â”‚
â”‚   â””â”€â”€ daily/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”‚
â”‚       â”œâ”€â”€ evening/                        # Evening jobs (6-8 PM)
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ dimension_sync.py           # â­ Accepts tenant_config param
â”‚       â”‚   â”œâ”€â”€ tsr_hierarchy.py
â”‚       â”‚   â”œâ”€â”€ refresh_matviews.py
â”‚       â”‚   â””â”€â”€ business_constants.py
â”‚       â”‚
â”‚       â””â”€â”€ morning/                        # Morning jobs (8 AM - 12 PM)
â”‚           â”œâ”€â”€ __init__.py
â”‚           â”œâ”€â”€ blob_backup.py
â”‚           â”œâ”€â”€ fis_incremental.py          # â­ Accepts tenant_config param
â”‚           â”œâ”€â”€ fid_incremental.py
â”‚           â””â”€â”€ dd_logic.py
â”‚
â”œâ”€â”€ config/                                  # LEGACY CONFIG (backward compatibility)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ settings.py                         # â­ Updated to support tenant context
â”‚   â”œâ”€â”€ database.py                         # â­ Updated with tenant-aware pooling
â”‚   â”œâ”€â”€ logging_config.py                   # Updated for per-tenant logs
â”‚   â””â”€â”€ storage.py                          # Azure storage helpers
â”‚
â”œâ”€â”€ scripts/                                 # UTILITY SCRIPTS
â”‚   â”œâ”€â”€ onboard_tenant.sh                   # â­ Tenant onboarding automation
â”‚   â”‚                                       # - Copies _template/
â”‚   â”‚                                       # - Prompts for config
â”‚   â”‚                                       # - Creates database
â”‚   â”œâ”€â”€ validate_tenant_config.py           # Config validation
â”‚   â””â”€â”€ migrate_single_to_multi.py          # Migration helper
â”‚
â”œâ”€â”€ tests/                                   # TESTS
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_core/
â”‚   â”‚   â”œâ”€â”€ test_extractors.py
â”‚   â”‚   â”œâ”€â”€ test_transformers.py
â”‚   â”‚   â””â”€â”€ test_loaders.py
â”‚   â”œâ”€â”€ test_orchestration/
â”‚   â”‚   â”œâ”€â”€ test_tenant_manager.py
â”‚   â”‚   â””â”€â”€ test_tenant_job_runner.py
â”‚   â””â”€â”€ test_integration/
â”‚       â””â”€â”€ test_end_to_end.py
â”‚
â”œâ”€â”€ docker-compose.yml                       # StarRocks infrastructure
â”œâ”€â”€ Dockerfile                               # Application container
â”œâ”€â”€ .env                                     # Global env vars (optional)
â”œâ”€â”€ .gitignore                               # âš ï¸ MUST ignore configs/tenants/*/.env
â”œâ”€â”€ requirements.txt                         # Python dependencies
â”œâ”€â”€ README.md                                # Project documentation
â”œâ”€â”€ MULTI_TENANT_SETUP.md                    # Multi-tenant onboarding guide
â””â”€â”€ DIRECTORY_STRUCTURE.md                   # â­ This file
```

---

## Data Flow: Source Files â†’ StarRocks

### Stage 1: Extraction (source_files/)
```
Azure Blob Storage
    â†“ (download)
DimMaterialMapping.csv.gz
    â†“ (decompress)
data/tenant1/historical/source_files/DimMaterialMapping.csv
```

### Stage 2: Raw Conversion (raw_parquet/) - Bronze Layer
```
core/transformers/file_to_parquet.py

Input: source_files/DimMaterialMapping.csv
Output: raw_parquet/DimMaterialMapping.parquet
Action: Convert CSV â†’ Parquet (NO transformations)

Input: source_files/FactInvoice.xlsx
Output: raw_parquet/FactInvoice.parquet
Action: Convert Excel â†’ Parquet (NO transformations)

Input: source_files/AlreadyParquet.parquet
Output: raw_parquet/AlreadyParquet.parquet
Action: Copy file (NO conversion needed)
```

### Stage 3: Transformation (cleaned_parquet/) - Silver Layer
```
core/transformers/transformation_engine.py

Input: raw_parquet/DimMaterialMapping.parquet
Actions:
  1. Load column_mappings/01_dim_material_mapping.yaml
  2. Rename columns (materialcode â†’ material_code)
  3. Convert dtypes (STRING â†’ INT, FLOAT â†’ DECIMAL)
  4. Apply roundoff transformations
  5. Generate computed columns
  6. Validate schema
Output: cleaned_parquet/DimMaterialMapping.parquet
```

### Stage 4: Loading (StarRocks)
```
core/loaders/starrocks_loader.py

Input: cleaned_parquet/DimMaterialMapping.parquet
Action: Stream Load to datawiz_tenant1.dim_material_mapping
Protocol: HTTP Stream Load API
```

---

## Key File Descriptions

### `core/transformers/file_to_parquet.py`
**Purpose:** Universal file â†’ parquet converter

**Supported Input Formats:**
- CSV files (`.csv`)
- Excel files (`.xlsx`, `.xls`)
- Parquet files (`.parquet`) - copy only

**Behavior:**
```python
def convert_to_parquet(source_file, output_dir, tenant_config):
    """
    Converts any file type to parquet format.

    Args:
        source_file: Path to source file (CSV/Excel/Parquet)
        output_dir: Path to raw_parquet/ directory
        tenant_config: TenantConfig object

    Returns:
        Path to output parquet file

    Logic:
        IF file is CSV:
            - Use polars.scan_csv()
            - Convert to parquet with row_groups=100,000
        ELIF file is Excel:
            - Use polars.read_excel()
            - Convert to parquet with row_groups=100,000
        ELIF file is Parquet:
            - Copy file to output_dir (no conversion)
        ELSE:
            - Raise UnsupportedFileTypeError
    """
```

### `configs/tenant_registry.yaml`
**Purpose:** Master registry of all tenants

```yaml
tenants:
  - tenant_id: tenant1
    tenant_name: "Pidilite Mumbai Operations"
    enabled: true                           # Job runner will process
    database_name: "datawiz_tenant1"
    database_user: "tenant1_admin"
    azure_container: "pidilite-mumbai-prod"
    azure_folder_prefix: "synapse_data/"
    schedule_priority: 1                    # Lower = higher priority
    tier: premium

  - tenant_id: tenant2
    tenant_name: "Pidilite Delhi Operations"
    enabled: true
    database_name: "datawiz_tenant2"
    database_user: "tenant2_admin"
    azure_container: "pidilite-delhi-prod"
    azure_folder_prefix: "data_exports/"
    schedule_priority: 2
    tier: standard

  - tenant_id: tenant3
    tenant_name: "Pidilite South Region"
    enabled: false                          # NOT processed by job runner
    database_name: "datawiz_tenant3"
    database_user: "tenant3_admin"
    azure_container: "pidilite-south-prod"
    schedule_priority: 3
    tier: standard

global_config:
  max_concurrent_tenants: 1                 # Sequential execution
  tenant_timeout: 7200                      # 2 hours per tenant
  fail_fast: false                          # Continue on failure
  shared_starrocks_cluster: true
```

### `configs/tenants/tenant1/config.yaml`
**Purpose:** Tenant-specific configuration (non-sensitive)

```yaml
tenant_id: tenant1
tenant_name: "Pidilite Mumbai Operations"
enabled: true

# Database Configuration (passwords in .env)
database:
  database_name: "datawiz_tenant1"
  user: "tenant1_admin"
  host: "localhost"
  port: 9030
  http_port: 8040

# Azure Blob Storage (connection string in .env)
azure:
  container_name: "pidilite-mumbai-prod"
  folder_prefix: "synapse_data/"

# Data Paths (relative to project root)
data_paths:
  historical: "data/tenant1/data_historical"
  incremental: "data/tenant1/data_incremental"
  temp: "data/tenant1/temp"

# Logs (relative to project root)
logs:
  base_path: "logs/tenant1"

# Business Rules
business_rules:
  date_filter_start: "20230401"             # FactInvoiceSecondary filter
  sales_threshold: 10000                    # Business constants filter
  material_type_filter: ["ZFGD"]            # Secondary sales material type

# Scheduler Configuration
scheduler:
  timezone: "Asia/Kolkata"
  enable_evening_jobs: true
  enable_morning_jobs: true
  evening_start_time: "18:00"               # 6:00 PM
  morning_start_time: "09:00"               # 9:00 AM

# Observability
observability:
  service_name: "datawiz-tenant1"
  enable_tracing: true
  enable_metrics: true
```

### `configs/tenants/tenant1/.env`
**Purpose:** Tenant secrets (âš ï¸ NEVER COMMIT!)

```bash
# Database Credentials
DB_PASSWORD=tenant1_secure_password_here

# Azure Storage
AZURE_STORAGE_CONNECTION_STRING=DefaultEndpointsProtocol=https;AccountName=...
AZURE_SAS_TOKEN=sv=2023-01-01&st=2025-01-15...

# MongoDB (if used for business constants)
MONGODB_URI=mongodb://tenant1_user:tenant1_pass@localhost:27017

# Email Notifications
SMTP_PASSWORD=email_password_here
EMAIL_RECIPIENTS=tenant1-admin@pidilite.com,ops@pidilite.com
```

---

## Configuration Hierarchy

```
Global Defaults (configs/shared/default_config.yaml)
    â†“ (overridden by)
Tenant Config (configs/tenants/tenant1/config.yaml)
    â†“ (secrets from)
Tenant Secrets (configs/tenants/tenant1/.env)
```

---

## Tenant Onboarding Process

### Step 1: Copy Template
```bash
cp -r configs/tenants/_template configs/tenants/tenant_new
```

### Step 2: Configure Tenant
```bash
# Edit config.yaml
vim configs/tenants/tenant_new/config.yaml

# Add secrets to .env
vim configs/tenants/tenant_new/.env
```

### Step 3: Register Tenant
```bash
# Add entry to tenant_registry.yaml
vim configs/tenant_registry.yaml
```

### Step 4: Create Database
```sql
CREATE DATABASE datawiz_tenant_new;
CREATE USER 'tenant_new_admin'@'%' IDENTIFIED BY 'password';
GRANT ALL PRIVILEGES ON datawiz_tenant_new.* TO 'tenant_new_admin'@'%';
```

### Step 5: Initialize Schema
```bash
python db/create_tables.py --tenant tenant_new
python db/load_seed_data.py --tenant tenant_new
```

### Step 6: Create Data Directories
```bash
mkdir -p data/tenant_new/{historical,incremental}/{source_files,raw_parquet,cleaned_parquet}
mkdir -p data/tenant_new/temp
mkdir -p logs/tenant_new/{scheduler,etl,notifications}
```

### Step 7: Enable Tenant
```yaml
# In tenant_registry.yaml
tenants:
  - tenant_id: tenant_new
    enabled: true  # Change to true
```

---

## Orchestration Flow

### Job Execution (Evening Dimension Sync Example)

```
1. scheduler/orchestrator.py starts
    â†“
2. Load tenant_registry.yaml
    â†“
3. Initialize TenantManager
    â†“
4. Get enabled tenants: [tenant1, tenant2]
    â†“
5. For each tenant (sequential):

    TENANT 1:
    â”œâ”€ Load configs/tenants/tenant1/config.yaml
    â”œâ”€ Load configs/tenants/tenant1/.env
    â”œâ”€ Create TenantConfig object
    â”œâ”€ Call dimension_sync(tenant_config)
    â”‚   â”œâ”€ Download from Azure (pidilite-mumbai-prod)
    â”‚   â”œâ”€ Save to data/tenant1/historical/source_files/
    â”‚   â”œâ”€ Convert to parquet â†’ raw_parquet/
    â”‚   â”œâ”€ Transform â†’ cleaned_parquet/
    â”‚   â”œâ”€ Load to datawiz_tenant1 database
    â”‚   â””â”€ Log to logs/tenant1/scheduler/
    â””â”€ Mark complete

    TENANT 2:
    â”œâ”€ Load configs/tenants/tenant2/config.yaml
    â”œâ”€ Load configs/tenants/tenant2/.env
    â”œâ”€ Create TenantConfig object
    â”œâ”€ Call dimension_sync(tenant_config)
    â”‚   â”œâ”€ Download from Azure (pidilite-delhi-prod)
    â”‚   â”œâ”€ Save to data/tenant2/historical/source_files/
    â”‚   â”œâ”€ Convert to parquet â†’ raw_parquet/
    â”‚   â”œâ”€ Transform â†’ cleaned_parquet/
    â”‚   â”œâ”€ Load to datawiz_tenant2 database
    â”‚   â””â”€ Log to logs/tenant2/scheduler/
    â””â”€ Mark complete

6. All tenants processed
```

---

## Security Best Practices

### 1. Secrets Management
- âœ… Store secrets in `.env` files per tenant
- âœ… Add `configs/tenants/*/.env` to `.gitignore`
- âœ… Never commit passwords, tokens, or connection strings
- âš ï¸ Consider HashiCorp Vault for production

### 2. Database Isolation
- âœ… Separate database per tenant (`datawiz_tenant1`, `datawiz_tenant2`)
- âœ… Separate database users per tenant
- âœ… Tenant-aware connection pooling (no cross-contamination)

### 3. Data Isolation
- âœ… Separate data directories per tenant (`data/tenant1/`, `data/tenant2/`)
- âœ… Separate log directories per tenant (`logs/tenant1/`, `logs/tenant2/`)
- âœ… No shared file paths between tenants

### 4. Access Control
- âœ… RLS (Row-Level Security) policies in `business_logic/rls_config.py`
- âœ… Territory-based filtering (`wss_territory_code`)
- âœ… Role-based access control

---

## Scalability Considerations

### 2-5 Tenants (Current)
- **Config Structure:** Flat (`configs/tenants/tenant1/`)
- **Execution:** Sequential (one tenant at a time)
- **Complexity:** Low
- **Maintenance:** Simple

### 6-10 Tenants (Growth)
- **Config Structure:** Still flat, consider tiering
- **Execution:** Parallel with limits (max 3 concurrent)
- **Complexity:** Medium
- **Maintenance:** Moderate

### 10+ Tenants (Enterprise)
- **Config Structure:** Nested by tier (`tier_1/tenant1/`, `tier_2/tenant5/`)
- **Execution:** Parallel with resource pools
- **Complexity:** High
- **Maintenance:** Requires automation

---

## Key Design Principles

1. **DRY (Don't Repeat Yourself)**
   - Core transformers are SHARED (no tenant prefixes)
   - Business logic is TENANT-SPECIFIC (in configs)

2. **Separation of Concerns**
   - Code in `core/` (business-agnostic)
   - Config in `configs/tenants/` (business-specific)
   - Data in `data/` (per-tenant isolation)

3. **Single Source of Truth**
   - `tenant_registry.yaml` = master tenant list
   - `config.yaml` = tenant configuration
   - `.env` = tenant secrets

4. **Fail-Safe Defaults**
   - Continue to next tenant on failure (`fail_fast: false`)
   - Timeout per tenant (2 hours)
   - Comprehensive logging

5. **Security by Design**
   - Separate databases per tenant
   - Separate credentials per tenant
   - Secrets in `.env` files (gitignored)

---

## Common Operations

### Check Active Tenants
```bash
python -c "from orchestration.tenant_manager import TenantManager; \
           tm = TenantManager('configs'); \
           print([t.tenant_id for t in tm.get_all_enabled_tenants()])"
```

### Run Job for Single Tenant
```bash
python scheduler/daily/evening/dimension_sync.py --tenant tenant1
```

### Run Job for All Tenants
```bash
python scheduler/orchestrator.py --job evening_dimension_sync
```

### Validate Tenant Config
```bash
python scripts/validate_tenant_config.py --tenant tenant1
```

### Disable Tenant
```yaml
# Edit tenant_registry.yaml
tenants:
  - tenant_id: tenant1
    enabled: false  # Change to false
```

---

## Migration Path (Single â†’ Multi-Tenant)

### Current State (Single Tenant)
```
db/schemas/
db/column_mappings/
db/seeds/
```

### Target State (Multi-Tenant)
```
configs/tenants/tenant1/schemas/
configs/tenants/tenant1/column_mappings/
configs/tenants/tenant1/seeds/
```

### Migration Script
```bash
python scripts/migrate_single_to_multi.py --tenant-id tenant1
```

---

## Related Documentation

- **README.md** - Project overview
- **MULTI_TENANT_SETUP.md** - Detailed setup guide
- **configs/tenants/_template/** - Onboarding template
- **Plan File:** `/home/rahul/.claude/plans/jolly-noodling-zephyr.md`

---

**End of Directory Structure Reference**
