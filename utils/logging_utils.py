"""
Logging Utilities

Provides structured logging setup for pipeline jobs
"""

import logging
import logging.handlers
from pathlib import Path
from datetime import datetime
from typing import Optional

# Color codes for console output
RED = "\033[31m"
GREEN = "\033[32m"
YELLOW = "\033[33m"
BLUE = "\033[34m"
CYAN = "\033[36m"
RESET = "\033[0m"


class ColoredFormatter(logging.Formatter):
    """Custom formatter with colored output for different log levels"""

    COLORS = {
        "DEBUG": BLUE,
        "INFO": GREEN,
        "WARNING": YELLOW,
        "ERROR": RED,
        "CRITICAL": RED,
    }

    def format(self, record):
        levelname = record.levelname
        color = self.COLORS.get(levelname, RESET)

        # Format the log message
        formatted = super().format(record)

        # Apply color to level name
        colored_level = f"{color}{levelname}{RESET}"
        formatted = formatted.replace(levelname, colored_level, 1)

        return formatted


def setup_logger(
    name: str,
    log_file: Optional[Path] = None,
    level: int = logging.INFO,
    console_output: bool = True,
) -> logging.Logger:
    """Setup a structured logger with file and console handlers

    Args:
        name: Logger name (typically the module name)
        log_file: Optional path to log file
        level: Logging level (default: INFO)
        console_output: Whether to output to console (default: True)

    Returns:
        Configured logger instance

    Example:
        logger = setup_logger(
            "dimension_incremental",
            log_file=Path("logs/dimension_incremental.log")
        )
        logger.info("Processing started")
    """
    logger = logging.getLogger(name)
    logger.setLevel(level)

    # Remove existing handlers to avoid duplicates
    logger.handlers.clear()

    # Format string
    format_str = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    formatter = logging.Formatter(format_str)

    # Console handler with color
    if console_output:
        console_handler = logging.StreamHandler()
        console_handler.setLevel(level)

        colored_formatter = ColoredFormatter(format_str)
        console_handler.setFormatter(colored_formatter)
        logger.addHandler(console_handler)

    # File handler
    if log_file:
        log_file.parent.mkdir(parents=True, exist_ok=True)

        file_handler = logging.handlers.RotatingFileHandler(
            log_file,
            maxBytes=10 * 1024 * 1024,  # 10 MB
            backupCount=5,
        )
        file_handler.setLevel(level)
        file_handler.setFormatter(formatter)
        logger.addHandler(file_handler)

    return logger


def get_pipeline_logger(
    service_name: str,
    logs_dir: Path = Path("logs"),
) -> logging.Logger:
    """Get a configured logger for pipeline services

    Args:
        service_name: Name of the service/job
        logs_dir: Directory to store log files

    Returns:
        Configured logger instance

    Example:
        logger = get_pipeline_logger("daily-dimension-incremental")
        logger.info("Pipeline started")
    """
    log_file = logs_dir / f"{service_name}_{datetime.now().strftime('%Y%m%d')}.log"
    return setup_logger(service_name, log_file=log_file, console_output=True)


def log_separator(logger: logging.Logger, title: Optional[str] = None):
    """Log a visual separator line

    Args:
        logger: Logger instance
        title: Optional title to display in separator

    Example:
        log_separator(logger, "Pipeline Starting")
        # Logs: ======== Pipeline Starting ========
    """
    separator = "=" * 100
    if title:
        logger.info(f"{separator}\n{title}\n{separator}")
    else:
        logger.info(separator)


def log_step(logger: logging.Logger, step_num: int, total_steps: int, description: str):
    """Log a pipeline step with progress

    Args:
        logger: Logger instance
        step_num: Current step number
        total_steps: Total number of steps
        description: Step description

    Example:
        log_step(logger, 1, 5, "Downloading blobs from Azure")
    """
    logger.info(f"\n[Step {step_num}/{total_steps}] {description}")


def log_summary(
    logger: logging.Logger,
    total_time: float,
    success_count: int,
    fail_count: int,
    total_records: int = 0,
):
    """Log a pipeline execution summary

    Args:
        logger: Logger instance
        total_time: Total execution time in seconds
        success_count: Number of successful operations
        fail_count: Number of failed operations
        total_records: Total records processed (optional)

    Example:
        log_summary(logger, 125.5, 4, 1, 100000)
    """
    logger.info("\n" + "=" * 100)
    logger.info("ğŸ“Š Execution Summary:")
    logger.info(f"  âœ… Successful: {success_count}")
    logger.info(f"  âŒ Failed: {fail_count}")
    if total_records > 0:
        logger.info(f"  ğŸ“ˆ Records processed: {total_records:,}")
    logger.info(f"  â±ï¸  Total time: {total_time:.2f}s")
    logger.info("=" * 100 + "\n")
